---
title: "XgfRiction Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{XgfRictionVignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Load the necessary libraries

```{r setup}
library(XgfRiction)
```

Let's first start by loading in the data frame that we will be working with. In this case, we are loading in data from a local file on a computer.

```{r}

file_path <- "~/Documents/GitHub/XgfRictionn/XgfRiction/ExampleData.csv"

# Load the data from the CSV file
ExampleData <- read.csv(file_path)

```

# Posix Data Format

The first thing that we need to do is make sure that our date and time column is in the POSIX format before we can make our class. We can then see what the update data frame looks like to make sure that it worked.

```{r}

# Define column names for date and time
year_col <- "YEAR"
month_col <- "MONTH"
day_col <- "DAY"
hour_col <- "HOUR"
min_col <- "MINUTE"
date_format <- "YMDHM"  # Specify the date format
posix_time_col <- "DateTime"  # Specify the name of the POSIX time column

# Convert the date and time columns to POSIXct format
converted_data <- convert_to_POSIX(ExampleData, date_format, year_col, month_col, day_col, hour_col, min_col, posix_time_col)

# Print the first few rows of the converted data to verify the conversion
head(converted_data)

```

# Check and update DateTime format function if needed

This example demonstrates how to use the check_and_update_datetime_format function to ensure the DateTime column is in the correct format (00:00 or 00:30) and adjust it if necessary. In this case, it is necessary. This package relies on the data being in a 30-minute data format. Some site data does not come in this format, so this function can standardized that if it is not in the correct format. Other formats typically include the 00:15 and 00:45 format.

```{r}
# Define the column containing the POSIXct (DateTime) data
posix_time_col <- "DateTime"

# Use the function to adjust the DateTime column by subtracting 15 minutes
adjusted_data <- subtract_15_minutes_from_datetime(converted_data, posix_time_col)

# The adjusted_data 
```

# 4. Calculate VPD and Tair function

In this example, the function calculate_vpd_and_tair calculates the VPD and Tair for a given data frame. This has already been done for this example data, so this is commented out. However, this use a look up table and MDS methods.

```{r}
# Define relative humidity and air temperature columns
#rh_col <- "Rh"  # Name of the relative humidity column
#tair_col <- "Tair"  # Name of the air temperature column

# Calculate VPD and Tair
#adjusted_data <- calculate_vpd_and_tair(adjusted_data, rh_col, tair_col)
```

# Initializing the user_class processor function

In this example, we'll use the initialize_user_class_processor function to initialize a sEddyProc object and set location information for the eddy covariance data.

```{r}

# Define site ID and data frame
site_ID <- "US-Bar"  # Site ID from the AmeriFlux website
data <- adjusted_data # Data frame containing eddy covariance data

# Define column names and POSIX time column
column_names <- c("NEE", "Rg", "Tair", "VPD", "Ustar")  # Vector of column names for eddy covariance data
posix_time_col <- "DateTime"  # Name of the POSIXct column in your data frame

# Define location information
LatDeg <- 44.0646  # Latitude of the site
LongDeg <- -71.2881  # Longitude of the site
TimeZoneHour <- -5  # Time zone offset in hours

# Initialize the user_class processor
user_class <- initialize_user_class_processor(
    site_ID = site_ID,
    data = data,
    column_names = column_names,
    posix_time_column = posix_time_col,
    LatDeg = LatDeg,
    LongDeg = LongDeg,
    TimeZoneHour = TimeZoneHour
)

```

# IQR Filtering Data

This example demonstrates how to use the function to perform IQR filtering on specified variables in a data frame and update the class with this additional filtering.

```{r}
# Perform IQR filtering on specified variables
#variables_to_filter <- c("NEE")
#threshold_multiplier <- 6  # The multiplier for the IQR threshold

# Apply the perform_iqr_filtering function
#xgfriction_proc <- perform_iqr_filtering(
   # xgfriction_proc = user_class,
    # dataframe = adjusted_data,
    # variables = variables_to_filter,
   # threshold_multiplier = threshold_multiplier
# )
```

# Practical Use of gap_fill_met_data Function:

To perform gap-filling of meteorological data for an XGFrictionProcessor object, you can use the gap_fill_met_data function. This function accepts an XGFrictionProcessor object, a vector of variable names you want to gap-fill, and a logical flag fill_all to specify whether to fill all gaps in the variables or only the missing values between two valid observations. This has already been done for this dataframe.

```{r}
# Define the variables to gap-fill
#variables_to_fill <- c("Tair", "VPD", "Rg")

# Perform gap-filling of specified variables
#gap_filled_processor <- gap_fill_met_data(user_class, variables_to_fill, fill_all = FALSE)

# The gap-filled processor object can now be used for further processing

```

# Estimate u\* Threshold Distribution

The function uses the sEstUstarThresholdDistribution method from the REddyProc package to estimate the u\* threshold distribution for the specified processor object.

```{r}
# Estimate the u* threshold distribution
ustar_distribution <- estimate_ustar_threshold_distribution(processor = user_class)
```

# Filter_ustar_by_mode

```{r}
# Filter the u* threshold distribution for the "year" aggregation mode
filtered_ustar <- filter_ustar_by_mode(ustar_distribution, mode = "year")

# Output the filtered data
head(filtered_ustar)

```

# get_ustar_annual

```{r}

# Obtain the annual or seasonal u* threshold map
uStarThAnnual <- get_ustar_annual(filtered_ustar)

```

# Obtain the uStar suffixes

```{r}
# Retrieve the column names of the u* threshold map
uStarSuffixes <- get_ustar_suffixes(uStarThAnnual)

# Print the u* suffixes
print(uStarSuffixes)

```

#Lets see what the fingerprint plot looks like

```{r}
user_class$sPlotFingerprintY('NEE', Year = 2010)
```

# Gap-Filling after uStar distribution selection and ustar filtering

```{r}
uStarThSingle <- uStarThAnnual[1, 1]

user_class$sMDSGapFillAfterUstar('NEE', uStarTh = uStarThSingle, FillAll = TRUE)


grep("NEE_.*_f$",names(user_class$sExportResults())
     , value = TRUE)
grep("NEE_.*_fsd$",names(user_class$sExportResults())
     , value = TRUE)
user_class.res <- user_class$sExportResults()
sum(is.na(user_class.res$NEE_uStar_f))
```

## Gap-Filling using XGBoost after uStar filtering using XGBoost instead of MDS methods

Step 1: Prepare Data First, let's prepare our data by splitting it into training and testing sets.

```{r}

# Select predictors and response variable
predictors <- c("TIMESTAMP_START", "TIMESTAMP_END", "Tair", "TS_F_1_2_1", "Rg", 
                "Rh", "PPFD_DIF_1_1_1", "PPFD_DIR_1_1_1", "NETRAD_1_1_1", 
                "SWC_1_1_1", "SWC_4_1_1", "VPD")
response <- "NEE"
ustar_threshold <- 0.2

# Filtered data containing only the necessary columns
filtered_data <- ExampleData[ExampleData$Ustar >= ustar_threshold, c(predictors, response)]

# Define formula for the model
formula <- reformulate(predictors, response)

# Prepare data
data_list <- prepare_data(filtered_data)

```

# Defining the model specifications

Next, let's define the model specification for the XGBoost model.

```{r}
# Create model specification
xgb_spec <- create_model_spec()

```

# Model Workflow

Now, let's create a workflow for training our XGBoost model.

```{r}
# Create workflow
workflow <- create_workflow(formula, xgb_spec)

```

# Cross Validation

Defining our Cross-Validation Folds

```{r}
# Define cross-validation folds
cv_folds <- create_cv_folds(data = data_list$train_data, folds = 5, repeats = 2)
```

# Training our XGBoost Model

```{r}
# Define the number of folds and repeats for cross-validation
# cv_folds <- 5
# cv_repeats <- 2
# 
# # Create cross-validation folds
# cv <- vfold_cv(data_list$train_data, v = cv_folds, repeats = cv_repeats)
# trained_model <- train_xgboost_model(
# data = data_list$train_data,
# formula = formula,
# grid = grid,
# folds = cv_folds)

```
