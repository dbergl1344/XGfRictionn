---
title: "XgfRiction Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{XgfRictionVignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

#Load the necessary libraries

```{r setup}
library(XgfRiction)
#other libraries 
library(roxygen2)
library(devtools)
library(REddyProc)
library(Metrics)
library(stats)
library(tidymodels)
library(ggplot2)
library(parsnip)
library(tune)
library(base)
library(rsample)
library(caret)
library(xgboost)
library(pkgdown)
library(dplyr)
```

Let's first start by loading in the data frame that we will be working with. In this case, we are loading in data from a local file on a computer.

```{r}

file_path <- "~/Documents/GitHub/XgfRictionn/XgfRiction/ExampleData.csv"

# Load the data from the CSV file
ExampleData <- read.csv(file_path)

```

# XgfRiction_initialize Function Description

The XgfRiction_initialize function is a utility provided by the XgfRiction package to initialize an XGFrictionProcessor object for processing eddy covariance data. This function simplifies the setup process by automating the initialization of the processor object with essential parameters such as site ID, column names, POSIX time column, and location information.

Arguments: site_ID: Site ID from the AmeriFlux website. data: Data frame containing the eddy covariance data. column_names: Vector with selected column names from the data frame. posix_time_column: Column name containing POSIX time stamps. LatDeg: Latitude of the measurement site. LongDeg: Longitude of the measurement site. TimeZoneHour: Time zone offset in hours. Returns: An initialized XGFrictionProcessor object ready for further data processing and analysis.

```{r}

# Define column names for date and time
year_col <- "YEAR"
month_col <- "MONTH"
day_col <- "DAY"
hour_col <- "HOUR"
min_col <- "MINUTE"
date_format <- "YMDHM"  # Specify the date format
posix_time_col <- "DateTime"  # Specify the name of the POSIX time column

# Convert the date and time columns to POSIXct format
converted_data <- convert_to_POSIX(ExampleData, date_format, year_col, month_col, day_col, hour_col, min_col, posix_time_col)

# Print the first few rows of the converted data to verify the conversion
head(converted_data)

```

# Check and update DateTime format function if needed

This example demonstrates how to use the check_and_update_datetime_format function to ensure the DateTime column is in the correct format (00:00 or 00:30) and adjust it if necessary. In this case, it is necessary.

```{r}
# Define the column containing the POSIXct (DateTime) data
posix_time_col <- "DateTime"

# Use the function to adjust the DateTime column by subtracting 15 minutes
adjusted_data <- subtract_15_minutes_from_datetime(converted_data, posix_time_col)

# The adjusted_data 
```

# 4. Calculate VPD and Tair function

In this example, the function calculate_vpd_and_tair calculates the VPD and Tair for a given data frame. This has already been done for this example data, so this is commented out.

```{r}
# Define relative humidity and air temperature columns
#rh_col <- "Rh"  # Name of the relative humidity column
#tair_col <- "Tair"  # Name of the air temperature column

# Calculate VPD and Tair
#adjusted_data <- calculate_vpd_and_tair(adjusted_data, rh_col, tair_col)
```

# Initialzing the user_class processor function

In this example, we'll use the initialize_user_class_processor function to initialize a sEddyProc object and set location information for the eddy covariance data.

```{r}

# Define site ID and data frame
site_ID <- "US-Bar"  # Site ID from the AmeriFlux website
data <- adjusted_data # Data frame containing eddy covariance data

# Define column names and POSIX time column
column_names <- c("NEE", "Rg", "Tair", "VPD", "Ustar")  # Vector of column names for eddy covariance data
posix_time_col <- "DateTime"  # Name of the POSIXct column in your data frame

# Define location information
LatDeg <- 44.0646  # Latitude of the site
LongDeg <- -71.2881  # Longitude of the site
TimeZoneHour <- -5  # Time zone offset in hours

# Initialize the user_class processor
user_class <- initialize_user_class_processor(
    site_ID = site_ID,
    data = data,
    column_names = column_names,
    posix_time_column = posix_time_col,
    LatDeg = LatDeg,
    LongDeg = LongDeg,
    TimeZoneHour = TimeZoneHour
)

```

# IQR Filtering Data

This example demonstrates how to use the function to perform IQR filtering on specified variables in a data frame and update the class with this additional filtering.

```{r}
# Perform IQR filtering on specified variables
#variables_to_filter <- c("NEE")
#threshold_multiplier <- 6  # The multiplier for the IQR threshold

# Apply the perform_iqr_filtering function
#xgfriction_proc <- perform_iqr_filtering(
   # xgfriction_proc = user_class,
    # dataframe = adjusted_data,
    # variables = variables_to_filter,
   # threshold_multiplier = threshold_multiplier
# )
```

# Practical Use of gap_fill_met_data Function:

To perform gap-filling of meteorological data for an XGFrictionProcessor object, you can use the gap_fill_met_data function. This function accepts an XGFrictionProcessor object, a vector of variable names you want to gap-fill, and a logical flag fill_all to specify whether to fill all gaps in the variables or only the missing values between two valid observations. This has already been done for this dataframe.

```{r}
# Define the variables to gap-fill
#variables_to_fill <- c("Tair", "VPD", "Rg")

# Perform gap-filling of specified variables
#gap_filled_processor <- gap_fill_met_data(user_class, variables_to_fill, fill_all = FALSE)

# The gap-filled processor object can now be used for further processing

```

# Estimate u\* Threshold Distribution

The function uses the sEstUstarThresholdDistribution method from the REddyProc package to estimate the u\* threshold distribution for the specified processor object.

```{r}
# Estimate the u* threshold distribution
ustar_distribution <- estimate_ustar_threshold_distribution(processor = user_class)
```

# Filter_ustar_by_mode

```{r}
# Filter the u* threshold distribution for the "year" aggregation mode
filtered_ustar <- filter_ustar_by_mode(ustar_distribution, mode = "year")

# Output the filtered data
head(filtered_ustar)

```

# get_ustar_annual

```{r}

# Obtain the annual or seasonal u* threshold map
uStarThAnnual <- get_ustar_annual(filtered_ustar)

```

# Obtain the uStar suffixes

```{r}
# Retrieve the column names of the u* threshold map
uStarSuffixes <- get_ustar_suffixes(uStarThAnnual)

# Print the u* suffixes
print(uStarSuffixes)

```

# Gap-Filling after uStar distribution selection and ustar filtering

```{r}
uStarThSingle <- uStarThAnnual[1, 1]

user_class$sMDSGapFillAfterUstar('NEE', uStarTh = uStarThSingle, FillAll = TRUE)


grep("NEE_.*_f$",names(user_class$sExportResults())
     , value = TRUE)
grep("NEE_.*_fsd$",names(user_class$sExportResults())
     , value = TRUE)

```



# Gap-Filling using XgBoost after uStar filtering using XgBoost instead of MDS methods

```{r}
# Define your single uStar threshold value from the above code
ustar_threshold <- 0.2

# Select predictors and response variable
predictors <- c("TIMESTAMP_START", "TIMESTAMP_END", "Tair", "TS_F_1_2_1", "Rg", 
                "Rh", "PPFD_DIF_1_1_1", "PPFD_DIR_1_1_1", "NETRAD_1_1_1", 
                "SWC_1_1_1", "SWC_4_1_1", "VPD")
response <- "NEE"

# Filtered data containing only the necessary columns
filtered_data <- ExampleData[ExampleData$Ustar >= ustar_threshold, c(predictors, response)]

# Define formula for the model
formula <- reformulate(predictors, response)

# Define custom grid for hyperparameter tuning
grid <- expand.grid(
  tree_depth = c(3, 6, 9),
  min_n = c(5, 10, 15),
  loss_reduction = c(0.01, 0.1, 0.2),
  sample_size = c(0.5, 0.7, 0.9),
  mtry = c(3, 5, 7),
  learn_rate = c(0.01, 0.1, 0.2)
)

# Train XGBoost model
trained_model <- train_xgboost_model(data = filtered_data, formula = formula, grid = grid)




```

